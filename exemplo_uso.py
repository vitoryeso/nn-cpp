#!/usr/bin/env python3
"""
Exemplo de uso da aplica√ß√£o CLI para conversar com LLM
"""

from llm_cli import LLMChat

def exemplo_basico():
    """Exemplo b√°sico de uso da classe LLMChat"""
    print("=== Exemplo de Uso da Classe LLMChat ===\n")
    
    # Cria inst√¢ncia do chat
    chat = LLMChat("http://localhost:8000")
    
    # Verifica se o servidor est√° rodando
    if not chat.check_server_health():
        print("‚ùå Servidor n√£o est√° rodando. Inicie o servidor vLLM primeiro.")
        return
    
    print("‚úÖ Servidor conectado!")
    
    # Lista modelos dispon√≠veis
    models = chat.get_available_models()
    if models:
        print(f"üìã Modelos: {', '.join(models)}")
    
    # Exemplo de conversa
    print("\n--- Exemplo de Conversa ---")
    
    # Primeira mensagem
    resposta1 = chat.send_message("Ol√°! Como voc√™ est√°?")
    print(f"Usu√°rio: Ol√°! Como voc√™ est√°?")
    print(f"Assistente: {resposta1}\n")
    
    # Segunda mensagem (com contexto)
    resposta2 = chat.send_message("Qual √© a capital do Brasil?")
    print(f"Usu√°rio: Qual √© a capital do Brasil?")
    print(f"Assistente: {resposta2}\n")
    
    # Mostra hist√≥rico
    print("--- Hist√≥rico da Conversa ---")
    chat.show_history()
    
    # Limpa hist√≥rico
    print("\n--- Limpando Hist√≥rico ---")
    chat.clear_history()
    print("Hist√≥rico limpo!")

if __name__ == "__main__":
    exemplo_basico()
